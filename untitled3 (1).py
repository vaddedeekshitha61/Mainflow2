# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nFZbuY2MVL0J9vsjnBEo25xRuY7xgPmS
"""

from google.colab import files
import io

uploaded = files.upload()
CSV_PATH = list(uploaded.keys())[0]

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams["figure.figsize"] = (7, 4)
# Load the CSV
df = pd.read_csv(io.BytesIO(uploaded[CSV_PATH]), encoding="latin1")
print("Initial shape:", df.shape)
display(df.head(5))

print("Column names:", list(df.columns))
print("\nData types:\n", df.dtypes)
print("\nMissing values per column:\n", df.isnull().sum())
print("\nNumeric summary (describe):")
display(df.describe(include=[np.number]).T)

#Clean missing values + remove duplicates

num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
cat_cols = df.select_dtypes(exclude=[np.number]).columns.tolist()
df[num_cols] = df[num_cols].apply(lambda s: s.fillna(s.median()))

# Fill categorical NaN with "Missing"
for c in cat_cols:
    df[c] = df[c].fillna("Missing")
# Remove duplicates
dup_before = df.duplicated().sum()
df = df.drop_duplicates()
duplicates_removed = dup_before  # number removed
print("Duplicates removed:", duplicates_removed)
print("Shape after cleaning missing & duplicates:", df.shape)

#Outlier detection & handling

required_cols = ["Sales", "Profit"]
for col in required_cols:
    if col not in df.columns:
        raise ValueError(f"Required column '{col}' not found in the dataset.")

def remove_outliers_iqr(data, cols, k=1.5):
    mask = pd.Series(True, index=data.index)
    for col in cols:
        if pd.api.types.is_numeric_dtype(data[col]):
            Q1 = data[col].quantile(0.25)
            Q3 = data[col].quantile(0.75)
            IQR = Q3 - Q1
            lower, upper = Q1 - k*IQR, Q3 + k*IQR
            mask &= data[col].between(lower, upper)
    filtered = data[mask].copy()
    removed_count = len(data) - len(filtered)
    return filtered, removed_count

df_before_outliers = df.copy()
df, outliers_removed = remove_outliers_iqr(df, ["Sales", "Profit"], k=1.5)

print("Outliers removed (IQR on Sales & Profit):", outliers_removed)
print("Shape after outlier handling:", df.shape)

#Statistical analysis
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()
stats_df = pd.DataFrame({
    "mean": df[num_cols].mean(),
    "median": df[num_cols].median(),
    "std": df[num_cols].std(),
    "var": df[num_cols].var()
}).round(3)

print("Basic statistics (numeric columns):")
display(stats_df)

#Correlations
corr = df[num_cols].corr()
print("Correlation matrix:")
display(corr)

# Show strongest absolute correlations (optional)
pairs = []
for i, c1 in enumerate(corr.columns):
    for j, c2 in enumerate(corr.columns):
        if j > i:
            pairs.append((c1, c2, corr.loc[c1, c2]))
pairs_sorted = sorted(pairs, key=lambda x: -abs(x[2]))[:10]
print("\nTop correlation pairs (by |r|):")
for a, b, r in pairs_sorted:
    print(f"{a} vs {b}: r = {r:.3f}")

# Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt

# Features (X) and Target (y)
X = df[['Profit', 'Discount']]
y = df['Sales']

# Train-Test Split (80-20)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Predictions
y_pred = model.predict(X_test)

# Model Evaluation
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("ðŸ”¹ Linear Regression Model Performance")
print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"RÂ² Score: {r2:.2f}")

# Coefficients
print("\nModel Coefficients:")
print(f"Intercept: {model.intercept_:.2f}")
print(f"Profit Coefficient: {model.coef_[0]:.2f}")
print(f"Discount Coefficient: {model.coef_[1]:.2f}")

# Scatter plot: Actual vs Predicted
plt.figure(figsize=(6,6))
plt.scatter(y_test, y_pred, alpha=0.6, color='blue')
plt.plot([y.min(), y.max()], [y.min(), y.max()], 'r--')  # Line y=x
plt.xlabel("Actual Sales")
plt.ylabel("Predicted Sales")
plt.title("Actual vs Predicted Sales (Linear Regression)")
plt.show()

#Visualization
plt.figure(figsize=(12, 6))
df['Sales'].hist(bins=30, edgecolor='black')
plt.title("Distribution of Sales")
plt.xlabel("Sales")
plt.ylabel("Frequency")
plt.show()

# ---------------- Boxplot (to detect outliers) ----------------
plt.figure(figsize=(12, 6))
sns.boxplot(x=df['Profit'])
plt.title("Boxplot of Profit (Outlier Detection)")
plt.xlabel("Profit")
plt.show()

# ---------------- Heatmap (correlation matrix) ----------------
plt.figure(figsize=(10, 6))
corr = df.corr(numeric_only=True)
sns.heatmap(corr, annot=True, cmap="coolwarm", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()



"""Summary Report â€“ Key Findings

1.Data Quality:



 No major missing values were found.
 Some duplicate rows exist and should be removed for better integrity.







2.Trends & Patterns



Sales values are highly variable â€” a small number of very large transactions
  List item

influence overall revenue.

Profit distribution shows both gains and heavy losses â†’ certain products or discounts lead to negative profit.

Discounts are negatively correlated with profit, meaning higher discounts often reduce profitability.

Quantity ordered shows weak correlation with profit â€” selling more units does not always mean more profit.

3.Anomalies & Outliers

Extreme outliers exist in Sales and Profit, which may distort analysis.

Some transactions result in large losses, likely due to over-discounting or unprofitable product categories.

4.Recommendations

Remove duplicates and handle outliers to make the dataset more reliable.

Investigate product categories/regions with consistently negative profit margins.

Optimize discount strategy â€” high discounts may be harming overall profitability.
"""